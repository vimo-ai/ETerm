//! Atomic Cache - åŸå­ç¼“å­˜
//!
//! èŒè´£ï¼šæä¾›çº¿ç¨‹å®‰å…¨çš„æ— é”ç¼“å­˜
//!
//! ç”¨é€”ï¼š
//! - å…‰æ ‡ä½ç½®ç¼“å­˜ï¼ˆä¸»çº¿ç¨‹è¯»å–ï¼Œæ¸²æŸ“/PTY çº¿ç¨‹æ›´æ–°ï¼‰
//! - é€‰åŒºçŠ¶æ€ç¼“å­˜
//! - ç»ˆç«¯å…ƒæ•°æ®ç¼“å­˜

use std::sync::atomic::{AtomicU64, Ordering};

/// æ‰“åŒ…çš„å…‰æ ‡ä½ç½®
///
/// ä½¿ç”¨ 64 ä½åŸå­å˜é‡å­˜å‚¨å…‰æ ‡ä½ç½®ï¼Œå®ç°æ— é”è¯»å†™ï¼š
/// - bits 0-15: col (u16)
/// - bits 16-31: row (u16)
/// - bits 32-47: display_offset (u16)
/// - bit 48: valid (bool)
/// - bits 49-63: reserved
#[derive(Debug)]
pub struct AtomicCursorCache {
    packed: AtomicU64,
}

impl AtomicCursorCache {
    /// åˆ›å»ºæ–°çš„åŸå­å…‰æ ‡ç¼“å­˜
    pub fn new() -> Self {
        Self {
            packed: AtomicU64::new(0), // åˆå§‹ä¸ºæ— æ•ˆ
        }
    }

    /// æ‰“åŒ…å…‰æ ‡ä½ç½®
    #[inline]
    fn pack(col: u16, row: u16, display_offset: u16, valid: bool) -> u64 {
        let mut packed = col as u64;
        packed |= (row as u64) << 16;
        packed |= (display_offset as u64) << 32;
        if valid {
            packed |= 1u64 << 48;
        }
        packed
    }

    /// è§£åŒ…å…‰æ ‡ä½ç½®
    #[inline]
    fn unpack(packed: u64) -> (u16, u16, u16, bool) {
        let col = (packed & 0xFFFF) as u16;
        let row = ((packed >> 16) & 0xFFFF) as u16;
        let display_offset = ((packed >> 32) & 0xFFFF) as u16;
        let valid = (packed >> 48) & 1 != 0;
        (col, row, display_offset, valid)
    }

    /// æ›´æ–°å…‰æ ‡ä½ç½®ï¼ˆç”Ÿäº§è€…è°ƒç”¨ï¼šPTY çº¿ç¨‹æˆ–æ¸²æŸ“çº¿ç¨‹ï¼‰
    ///
    /// # å‚æ•°
    /// - col: å…‰æ ‡åˆ—ï¼ˆå±å¹•åæ ‡ï¼‰
    /// - row: å…‰æ ‡è¡Œï¼ˆå±å¹•åæ ‡ï¼Œç›¸å¯¹äºå½“å‰ display_offsetï¼‰
    /// - display_offset: å½“å‰æ˜¾ç¤ºåç§»
    #[inline]
    pub fn update(&self, col: u16, row: u16, display_offset: u16) {
        let packed = Self::pack(col, row, display_offset, true);
        self.packed.store(packed, Ordering::Release);
    }

    /// è¯»å–å…‰æ ‡ä½ç½®ï¼ˆæ¶ˆè´¹è€…è°ƒç”¨ï¼šä¸»çº¿ç¨‹ï¼‰
    ///
    /// # è¿”å›
    /// - `Some((col, row, display_offset))` - æœ‰æ•ˆçš„å…‰æ ‡ä½ç½®
    /// - `None` - ç¼“å­˜æ— æ•ˆ
    #[inline]
    pub fn read(&self) -> Option<(u16, u16, u16)> {
        let packed = self.packed.load(Ordering::Acquire);
        let (col, row, display_offset, valid) = Self::unpack(packed);
        if valid {
            Some((col, row, display_offset))
        } else {
            None
        }
    }

    /// æ ‡è®°ç¼“å­˜æ— æ•ˆ
    #[inline]
    pub fn invalidate(&self) {
        self.packed.store(0, Ordering::Release);
    }

    /// æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    #[inline]
    pub fn is_valid(&self) -> bool {
        let packed = self.packed.load(Ordering::Acquire);
        (packed >> 48) & 1 != 0
    }
}

impl Default for AtomicCursorCache {
    fn default() -> Self {
        Self::new()
    }
}

/// æ‰“åŒ…çš„ç»ˆç«¯è„æ ‡è®°
///
/// ä½¿ç”¨åŸå­ bool æ ‡è®°ç»ˆç«¯æ˜¯å¦éœ€è¦æ¸²æŸ“
#[derive(Debug)]
pub struct AtomicDirtyFlag {
    dirty: std::sync::atomic::AtomicBool,
}

impl AtomicDirtyFlag {
    /// åˆ›å»ºæ–°çš„è„æ ‡è®°ï¼ˆåˆå§‹ä¸ºè„ï¼‰
    pub fn new() -> Self {
        Self {
            dirty: std::sync::atomic::AtomicBool::new(true),
        }
    }

    /// æ ‡è®°ä¸ºè„
    #[inline]
    pub fn mark_dirty(&self) {
        self.dirty.store(true, Ordering::Release);
    }

    /// æ£€æŸ¥å¹¶æ¸…é™¤è„æ ‡è®°
    ///
    /// è¿”å›ä¹‹å‰çš„è„çŠ¶æ€
    #[inline]
    pub fn check_and_clear(&self) -> bool {
        self.dirty.swap(false, Ordering::AcqRel)
    }

    /// æ£€æŸ¥æ˜¯å¦è„ï¼ˆä¸æ¸…é™¤ï¼‰
    #[inline]
    pub fn is_dirty(&self) -> bool {
        self.dirty.load(Ordering::Acquire)
    }
}

impl Default for AtomicDirtyFlag {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================================================
// P1.1: AtomicSelectionCache - é€‰åŒºç¼“å­˜
// ============================================================================

/// é€‰åŒºç¼“å­˜
///
/// ä½¿ç”¨ä¸¤ä¸ª AtomicU64 å­˜å‚¨é€‰åŒºèŒƒå›´ï¼Œå®ç°æ— é”è¯»å†™ï¼š
/// - start: (start_row << 32) | start_col
/// - end: (end_row << 32) | end_col | (valid << 63)
///
/// å†…å­˜å¸ƒå±€ï¼š
/// - bits 0-31: col (u32)
/// - bits 32-62: row (i31ï¼Œæ”¯æŒè´Ÿæ•°è¡Œå·)
/// - bit 63 (ä»… end): valid æ ‡è®°
#[derive(Debug)]
pub struct AtomicSelectionCache {
    /// é€‰åŒºèµ·ç‚¹ï¼š(row << 32) | col
    start: AtomicU64,
    /// é€‰åŒºç»ˆç‚¹ï¼š(row << 32) | col | (valid << 63)
    end: AtomicU64,
}

impl AtomicSelectionCache {
    /// åˆ›å»ºæ–°çš„é€‰åŒºç¼“å­˜ï¼ˆåˆå§‹æ— æ•ˆï¼‰
    pub fn new() -> Self {
        Self {
            start: AtomicU64::new(0),
            end: AtomicU64::new(0), // valid bit = 0
        }
    }

    /// æ‰“åŒ…åæ ‡
    #[inline]
    fn pack_coord(row: i32, col: u32) -> u64 {
        // row ä½¿ç”¨ä½ 31 ä½ï¼ˆå¸¦ç¬¦å·ï¼‰ï¼Œcol ä½¿ç”¨é«˜ 32 ä½
        let row_bits = (row as u32) as u64; // ä¿ç•™ç¬¦å·ä½
        let col_bits = (col as u64) << 32;
        row_bits | col_bits
    }

    /// è§£åŒ…åæ ‡
    #[inline]
    fn unpack_coord(packed: u64) -> (i32, u32) {
        let row = (packed & 0xFFFFFFFF) as i32;
        let col = ((packed >> 32) & 0x7FFFFFFF) as u32; // å»æ‰ valid bit
        (row, col)
    }

    /// æ›´æ–°é€‰åŒºï¼ˆç”Ÿäº§è€…è°ƒç”¨ï¼šæ¸²æŸ“çº¿ç¨‹ï¼‰
    ///
    /// # å‚æ•°
    /// - start_row, start_col: é€‰åŒºèµ·ç‚¹
    /// - end_row, end_col: é€‰åŒºç»ˆç‚¹
    #[inline]
    pub fn update(&self, start_row: i32, start_col: u32, end_row: i32, end_col: u32) {
        let start_packed = Self::pack_coord(start_row, start_col);
        let end_packed = Self::pack_coord(end_row, end_col) | (1u64 << 63); // è®¾ç½® valid bit

        self.start.store(start_packed, Ordering::Release);
        self.end.store(end_packed, Ordering::Release);
    }

    /// è¯»å–é€‰åŒºï¼ˆæ¶ˆè´¹è€…è°ƒç”¨ï¼šä¸»çº¿ç¨‹ï¼‰
    ///
    /// # è¿”å›
    /// - `Some((start_row, start_col, end_row, end_col))` - æœ‰æ•ˆé€‰åŒº
    /// - `None` - æ— é€‰åŒº
    #[inline]
    pub fn read(&self) -> Option<(i32, u32, i32, u32)> {
        let end_packed = self.end.load(Ordering::Acquire);
        let valid = (end_packed >> 63) & 1 != 0;

        if !valid {
            return None;
        }

        let start_packed = self.start.load(Ordering::Acquire);
        let (start_row, start_col) = Self::unpack_coord(start_packed);
        let (end_row, end_col) = Self::unpack_coord(end_packed);

        Some((start_row, start_col, end_row, end_col))
    }

    /// æ¸…é™¤é€‰åŒº
    #[inline]
    pub fn clear(&self) {
        self.end.store(0, Ordering::Release); // valid bit = 0
    }

    /// æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆé€‰åŒº
    #[inline]
    pub fn has_selection(&self) -> bool {
        let end_packed = self.end.load(Ordering::Acquire);
        (end_packed >> 63) & 1 != 0
    }
}

impl Default for AtomicSelectionCache {
    fn default() -> Self {
        Self::new()
    }
}

// ============================================================================
// P1.2: AtomicTitleCache - æ ‡é¢˜ç¼“å­˜
// ============================================================================

use std::sync::atomic::AtomicPtr;
use std::ptr;

/// æ ‡é¢˜ç¼“å­˜
///
/// ä½¿ç”¨ AtomicPtr<String> å®ç°æ— é”æ ‡é¢˜æ›´æ–°
/// é‡‡ç”¨ RCU (Read-Copy-Update) æ¨¡å¼ï¼š
/// - æ›´æ–°æ—¶åˆ†é…æ–° Stringï¼ŒåŸå­äº¤æ¢æŒ‡é’ˆ
/// - è¯»å–æ—¶å…‹éš†å½“å‰å€¼
/// - æ—§å€¼é€šè¿‡ Box è‡ªåŠ¨é‡Šæ”¾
#[derive(Debug)]
pub struct AtomicTitleCache {
    /// æŒ‡å‘å †åˆ†é…çš„ String
    ptr: AtomicPtr<String>,
}

impl AtomicTitleCache {
    /// åˆ›å»ºæ–°çš„æ ‡é¢˜ç¼“å­˜ï¼ˆåˆå§‹ä¸ºç©ºï¼‰
    pub fn new() -> Self {
        Self {
            ptr: AtomicPtr::new(ptr::null_mut()),
        }
    }

    /// æ›´æ–°æ ‡é¢˜ï¼ˆç”Ÿäº§è€…è°ƒç”¨ï¼šPTY çº¿ç¨‹ï¼‰
    ///
    /// # å‚æ•°
    /// - title: æ–°æ ‡é¢˜
    pub fn update(&self, title: &str) {
        // åˆ†é…æ–° String
        let new_ptr = Box::into_raw(Box::new(title.to_string()));

        // åŸå­äº¤æ¢æŒ‡é’ˆ
        let old_ptr = self.ptr.swap(new_ptr, Ordering::AcqRel);

        // é‡Šæ”¾æ—§å€¼
        if !old_ptr.is_null() {
            unsafe {
                drop(Box::from_raw(old_ptr));
            }
        }
    }

    /// è¯»å–æ ‡é¢˜ï¼ˆæ¶ˆè´¹è€…è°ƒç”¨ï¼šä¸»çº¿ç¨‹ï¼‰
    ///
    /// # è¿”å›
    /// - `Some(String)` - å½“å‰æ ‡é¢˜
    /// - `None` - æ— æ ‡é¢˜
    pub fn read(&self) -> Option<String> {
        let ptr = self.ptr.load(Ordering::Acquire);
        if ptr.is_null() {
            None
        } else {
            // å®‰å…¨ï¼šptr æŒ‡å‘æœ‰æ•ˆçš„ Stringï¼Œä¸”æˆ‘ä»¬åªè¯»å–
            unsafe { Some((*ptr).clone()) }
        }
    }

    /// æ¸…é™¤æ ‡é¢˜
    pub fn clear(&self) {
        let old_ptr = self.ptr.swap(ptr::null_mut(), Ordering::AcqRel);
        if !old_ptr.is_null() {
            unsafe {
                drop(Box::from_raw(old_ptr));
            }
        }
    }
}

impl Default for AtomicTitleCache {
    fn default() -> Self {
        Self::new()
    }
}

impl Drop for AtomicTitleCache {
    fn drop(&mut self) {
        let ptr = self.ptr.load(Ordering::Acquire);
        if !ptr.is_null() {
            unsafe {
                drop(Box::from_raw(ptr));
            }
        }
    }
}

// ============================================================================
// P1.3: AtomicScrollCache - æ»šåŠ¨ä½ç½®ç¼“å­˜
// ============================================================================

/// æ»šåŠ¨ä½ç½®ç¼“å­˜
///
/// ä½¿ç”¨ 64 ä½åŸå­å˜é‡å­˜å‚¨æ»šåŠ¨ä¿¡æ¯ï¼š
/// - bits 0-31: display_offset (u32)
/// - bits 32-47: history_size (u16ï¼Œæˆªæ–­å¤§å€¼)
/// - bits 48-62: total_lines (u15ï¼Œæˆªæ–­å¤§å€¼)
/// - bit 63: valid
#[derive(Debug)]
pub struct AtomicScrollCache {
    packed: AtomicU64,
}

impl AtomicScrollCache {
    /// åˆ›å»ºæ–°çš„æ»šåŠ¨ç¼“å­˜ï¼ˆåˆå§‹æ— æ•ˆï¼‰
    pub fn new() -> Self {
        Self {
            packed: AtomicU64::new(0),
        }
    }

    /// æ‰“åŒ…æ»šåŠ¨ä¿¡æ¯
    #[inline]
    fn pack(display_offset: u32, history_size: u16, total_lines: u16, valid: bool) -> u64 {
        let mut packed = display_offset as u64;
        packed |= (history_size as u64) << 32;
        packed |= ((total_lines & 0x7FFF) as u64) << 48; // åªç”¨ 15 ä½
        if valid {
            packed |= 1u64 << 63;
        }
        packed
    }

    /// è§£åŒ…æ»šåŠ¨ä¿¡æ¯
    #[inline]
    fn unpack(packed: u64) -> (u32, u16, u16, bool) {
        let display_offset = (packed & 0xFFFFFFFF) as u32;
        let history_size = ((packed >> 32) & 0xFFFF) as u16;
        let total_lines = ((packed >> 48) & 0x7FFF) as u16;
        let valid = (packed >> 63) & 1 != 0;
        (display_offset, history_size, total_lines, valid)
    }

    /// æ›´æ–°æ»šåŠ¨ä¿¡æ¯ï¼ˆç”Ÿäº§è€…è°ƒç”¨ï¼šæ¸²æŸ“çº¿ç¨‹ï¼‰
    ///
    /// # å‚æ•°
    /// - display_offset: å½“å‰æ˜¾ç¤ºåç§»
    /// - history_size: å†å²è¡Œæ•°
    /// - total_lines: æ€»è¡Œæ•°
    #[inline]
    pub fn update(&self, display_offset: u32, history_size: usize, total_lines: usize) {
        // æˆªæ–­å¤§å€¼åˆ° u16 èŒƒå›´
        let history_size = (history_size.min(u16::MAX as usize)) as u16;
        let total_lines = (total_lines.min(0x7FFF)) as u16; // 15 ä½

        let packed = Self::pack(display_offset, history_size, total_lines, true);
        self.packed.store(packed, Ordering::Release);
    }

    /// è¯»å–æ»šåŠ¨ä¿¡æ¯ï¼ˆæ¶ˆè´¹è€…è°ƒç”¨ï¼šä¸»çº¿ç¨‹ï¼‰
    ///
    /// # è¿”å›
    /// - `Some((display_offset, history_size, total_lines))` - æœ‰æ•ˆä¿¡æ¯
    /// - `None` - ç¼“å­˜æ— æ•ˆ
    #[inline]
    pub fn read(&self) -> Option<(u32, u16, u16)> {
        let packed = self.packed.load(Ordering::Acquire);
        let (display_offset, history_size, total_lines, valid) = Self::unpack(packed);
        if valid {
            Some((display_offset, history_size, total_lines))
        } else {
            None
        }
    }

    /// æ ‡è®°ç¼“å­˜æ— æ•ˆ
    #[inline]
    pub fn invalidate(&self) {
        self.packed.store(0, Ordering::Release);
    }

    /// æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    #[inline]
    pub fn is_valid(&self) -> bool {
        let packed = self.packed.load(Ordering::Acquire);
        (packed >> 63) & 1 != 0
    }
}

impl Default for AtomicScrollCache {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use std::thread;

    #[test]
    fn test_atomic_cursor_cache_basic() {
        let cache = AtomicCursorCache::new();

        // åˆå§‹çŠ¶æ€æ— æ•ˆ
        assert!(!cache.is_valid());
        assert!(cache.read().is_none());

        // æ›´æ–°
        cache.update(10, 5, 100);

        // è¯»å–
        assert!(cache.is_valid());
        let (col, row, offset) = cache.read().unwrap();
        assert_eq!(col, 10);
        assert_eq!(row, 5);
        assert_eq!(offset, 100);

        // å¤±æ•ˆ
        cache.invalidate();
        assert!(!cache.is_valid());
        assert!(cache.read().is_none());
    }

    #[test]
    fn test_atomic_cursor_cache_max_values() {
        let cache = AtomicCursorCache::new();

        // æµ‹è¯•æœ€å¤§å€¼
        cache.update(u16::MAX, u16::MAX, u16::MAX);

        let (col, row, offset) = cache.read().unwrap();
        assert_eq!(col, u16::MAX);
        assert_eq!(row, u16::MAX);
        assert_eq!(offset, u16::MAX);
    }

    #[test]
    fn test_atomic_cursor_cache_concurrent() {
        let cache = Arc::new(AtomicCursorCache::new());
        let cache_writer = Arc::clone(&cache);
        let cache_reader = Arc::clone(&cache);

        let iterations = 10000;

        // å†™çº¿ç¨‹
        let writer = thread::spawn(move || {
            for i in 0..iterations {
                let col = (i % 256) as u16;
                let row = (i % 128) as u16;
                cache_writer.update(col, row, 0);
            }
        });

        // è¯»çº¿ç¨‹
        let reader = thread::spawn(move || {
            let mut valid_reads = 0;
            for _ in 0..iterations {
                if cache_reader.read().is_some() {
                    valid_reads += 1;
                }
            }
            valid_reads
        });

        writer.join().unwrap();
        let valid_reads = reader.join().unwrap();

        // è‡³å°‘åº”è¯¥æœ‰ä¸€äº›æœ‰æ•ˆè¯»å–
        assert!(valid_reads > 0);
    }

    #[test]
    fn test_atomic_dirty_flag_basic() {
        let flag = AtomicDirtyFlag::new();

        // åˆå§‹çŠ¶æ€ä¸ºè„
        assert!(flag.is_dirty());

        // æ£€æŸ¥å¹¶æ¸…é™¤
        assert!(flag.check_and_clear());
        assert!(!flag.is_dirty());

        // å†æ¬¡æ£€æŸ¥
        assert!(!flag.check_and_clear());

        // æ ‡è®°ä¸ºè„
        flag.mark_dirty();
        assert!(flag.is_dirty());
    }

    #[test]
    fn test_atomic_dirty_flag_concurrent() {
        let flag = Arc::new(AtomicDirtyFlag::new());
        let flag_writer = Arc::clone(&flag);
        let flag_reader = Arc::clone(&flag);

        let iterations = 10000;

        // å†™çº¿ç¨‹
        let writer = thread::spawn(move || {
            for _ in 0..iterations {
                flag_writer.mark_dirty();
            }
        });

        // è¯»çº¿ç¨‹
        let reader = thread::spawn(move || {
            let mut dirty_count = 0;
            for _ in 0..iterations {
                if flag_reader.check_and_clear() {
                    dirty_count += 1;
                }
            }
            dirty_count
        });

        writer.join().unwrap();
        let dirty_count = reader.join().unwrap();

        // åº”è¯¥æœ‰ä¸€äº›è„æ£€æµ‹
        assert!(dirty_count > 0);
    }

    // ========================================================================
    // P1.1: AtomicSelectionCache æµ‹è¯•
    // ========================================================================

    #[test]
    fn test_atomic_selection_cache_basic() {
        let cache = AtomicSelectionCache::new();

        // åˆå§‹çŠ¶æ€æ— é€‰åŒº
        assert!(!cache.has_selection());
        assert!(cache.read().is_none());

        // æ›´æ–°é€‰åŒº
        cache.update(10, 5, 20, 15);

        // è¯»å–
        assert!(cache.has_selection());
        let (start_row, start_col, end_row, end_col) = cache.read().unwrap();
        assert_eq!(start_row, 10);
        assert_eq!(start_col, 5);
        assert_eq!(end_row, 20);
        assert_eq!(end_col, 15);

        // æ¸…é™¤
        cache.clear();
        assert!(!cache.has_selection());
        assert!(cache.read().is_none());
    }

    #[test]
    fn test_atomic_selection_cache_negative_rows() {
        let cache = AtomicSelectionCache::new();

        // æµ‹è¯•è´Ÿæ•°è¡Œå·ï¼ˆå†å²æ»šåŠ¨ï¼‰
        cache.update(-100, 0, 10, 80);

        let (start_row, start_col, end_row, end_col) = cache.read().unwrap();
        assert_eq!(start_row, -100);
        assert_eq!(start_col, 0);
        assert_eq!(end_row, 10);
        assert_eq!(end_col, 80);
    }

    #[test]
    fn test_atomic_selection_cache_concurrent() {
        let cache = Arc::new(AtomicSelectionCache::new());
        let cache_writer = Arc::clone(&cache);
        let cache_reader = Arc::clone(&cache);

        let iterations = 10000;

        let writer = thread::spawn(move || {
            for i in 0..iterations {
                let row = (i % 100) as i32;
                let col = (i % 80) as u32;
                cache_writer.update(row, col, row + 10, col + 20);
            }
        });

        let reader = thread::spawn(move || {
            let mut valid_reads = 0;
            for _ in 0..iterations {
                if cache_reader.read().is_some() {
                    valid_reads += 1;
                }
            }
            valid_reads
        });

        writer.join().unwrap();
        let valid_reads = reader.join().unwrap();
        assert!(valid_reads > 0);
    }

    // ========================================================================
    // P1.2: AtomicTitleCache æµ‹è¯•
    // ========================================================================

    #[test]
    fn test_atomic_title_cache_basic() {
        let cache = AtomicTitleCache::new();

        // åˆå§‹çŠ¶æ€æ— æ ‡é¢˜
        assert!(cache.read().is_none());

        // æ›´æ–°æ ‡é¢˜
        cache.update("Hello World");
        assert_eq!(cache.read(), Some("Hello World".to_string()));

        // æ›´æ–°æ–°æ ‡é¢˜
        cache.update("New Title");
        assert_eq!(cache.read(), Some("New Title".to_string()));

        // æ¸…é™¤
        cache.clear();
        assert!(cache.read().is_none());
    }

    #[test]
    fn test_atomic_title_cache_unicode() {
        let cache = AtomicTitleCache::new();

        // æµ‹è¯• Unicode æ ‡é¢˜
        cache.update("ç»ˆç«¯æ ‡é¢˜ ğŸš€");
        assert_eq!(cache.read(), Some("ç»ˆç«¯æ ‡é¢˜ ğŸš€".to_string()));
    }

    #[test]
    fn test_atomic_title_cache_concurrent() {
        let cache = Arc::new(AtomicTitleCache::new());
        let cache_writer = Arc::clone(&cache);
        let cache_reader = Arc::clone(&cache);

        let iterations = 1000;

        let writer = thread::spawn(move || {
            for i in 0..iterations {
                cache_writer.update(&format!("Title {}", i));
            }
        });

        let reader = thread::spawn(move || {
            let mut valid_reads = 0;
            for _ in 0..iterations {
                if cache_reader.read().is_some() {
                    valid_reads += 1;
                }
            }
            valid_reads
        });

        writer.join().unwrap();
        let valid_reads = reader.join().unwrap();
        assert!(valid_reads > 0);
    }

    // ========================================================================
    // P1.3: AtomicScrollCache æµ‹è¯•
    // ========================================================================

    #[test]
    fn test_atomic_scroll_cache_basic() {
        let cache = AtomicScrollCache::new();

        // åˆå§‹çŠ¶æ€æ— æ•ˆ
        assert!(!cache.is_valid());
        assert!(cache.read().is_none());

        // æ›´æ–°
        cache.update(100, 500, 1000);

        // è¯»å–
        assert!(cache.is_valid());
        let (offset, history, total) = cache.read().unwrap();
        assert_eq!(offset, 100);
        assert_eq!(history, 500);
        assert_eq!(total, 1000);

        // å¤±æ•ˆ
        cache.invalidate();
        assert!(!cache.is_valid());
        assert!(cache.read().is_none());
    }

    #[test]
    fn test_atomic_scroll_cache_max_values() {
        let cache = AtomicScrollCache::new();

        // æµ‹è¯•å¤§å€¼æˆªæ–­
        cache.update(u32::MAX, usize::MAX, usize::MAX);

        let (offset, history, total) = cache.read().unwrap();
        assert_eq!(offset, u32::MAX);
        assert_eq!(history, u16::MAX);
        assert_eq!(total, 0x7FFF); // 15 ä½æœ€å¤§å€¼
    }

    #[test]
    fn test_atomic_scroll_cache_concurrent() {
        let cache = Arc::new(AtomicScrollCache::new());
        let cache_writer = Arc::clone(&cache);
        let cache_reader = Arc::clone(&cache);

        let iterations = 10000;

        let writer = thread::spawn(move || {
            for i in 0..iterations {
                cache_writer.update(i as u32, i, i * 2);
            }
        });

        let reader = thread::spawn(move || {
            let mut valid_reads = 0;
            for _ in 0..iterations {
                if cache_reader.read().is_some() {
                    valid_reads += 1;
                }
            }
            valid_reads
        });

        writer.join().unwrap();
        let valid_reads = reader.join().unwrap();
        assert!(valid_reads > 0);
    }
}
